{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implemenatation of https://arxiv.org/pdf/1703.07754.pdf\n",
    "\n",
    "# To do \n",
    "\n",
    "# create basic model bidirectional architecture [ Done ]\n",
    "# glove initialization [ Done ]\n",
    "# ctc integration \n",
    "# dataset preparation [ Done ]\n",
    "# feature extraction [ Done ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import logfbank\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We extracted 40-dimensional logMel filterbank energies over\n",
    "25 ms frames every 10 ms from the input speech signal, stacked\n",
    "two successive frames, and dropped every alternate frame resulting\n",
    "in 80-dimensional logMel features at half the rate of the\n",
    "original 40-dimensional features. This ”stacking+decimation”\n",
    "operation [16] provided significant speed-up in training because\n",
    "the sequence length reduces by half with no loss in performance '''\n",
    "\n",
    "\n",
    "def audio_to_features(fileurl):\n",
    "    rate, sig = wav.read(fileurl)\n",
    "  #  mfcc_feat = mfcc(sig,rate)\n",
    "#d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "    fbank_feat = logfbank(sig,rate,nfilt=40)\n",
    "    \n",
    "\n",
    "    \n",
    "    # if length of frames is even no problemo, otherwise add a new frame of zeroes\n",
    "    \n",
    "    if fbank_feat.shape[0]%2 == 0:\n",
    "        print('even')\n",
    "        fbank_feat = np.reshape(fbank_feat, (fbank_feat.shape[0]/2,80))\n",
    "        return fbank_feat\n",
    "    else:\n",
    "        print('odd')\n",
    "        print(fbank_feat.shape)\n",
    "        \n",
    "        zero_array=np.zeros(40)\n",
    "      #  print(zero_array)\n",
    "       \n",
    "        fbank_feat =          np.vstack((fbank_feat , zero_array))\n",
    "        #print(fbank_feat.shape)\n",
    "        \n",
    "        new_length=fbank_feat.shape[0]//2\n",
    "        \n",
    "        fbank_feat = np.reshape(fbank_feat, ( new_length ,80))\n",
    "        return fbank_feat\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odd\n",
      "(299, 40)\n",
      "(300, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 80)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_to_features('/home/saurabh/Documents/tf_orange/tf_orange/data/test.wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_csv(line):\n",
    "       parsed_line = tf.decode_csv(line, [[\"\"],[\"\"]])\n",
    "       \n",
    "    \n",
    "       \n",
    "       \n",
    "\n",
    "       return parsed_line[0] , parsed_line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _read_py_function(audio, label):\n",
    "    audio =audio_to_features(audio)\n",
    "   \n",
    "    return audio ,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.contrib.data.TextLineDataset(\"/home/saurabh/Documents/tf_orange/tf_orange/data/data.csv\")\n",
    "dataset=dataset.map(decode_csv)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda audio, label: tuple(tf.py_func(\n",
    "        _read_py_function, [audio, label], [tf.double, label.dtype])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset=dataset.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 2\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "vocab_size=100 # this means number of words at output layer, CTC blank symbol exluded\n",
    "num_input = 80# \n",
    "timesteps = 300 # timesteps\n",
    "num_hidden = 320 # hidden layer num of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to load pretrained gloVe model\n",
    "\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "\n",
    "#vocab,embd = loadGloVe(filename)\n",
    "#vocab_size = len(vocab)\n",
    "#embedding_dim = len(embd[0])\n",
    "#embedding = np.asarray(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "\n",
    "#W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]),\n",
    " #               trainable=False, name=\"W\")\n",
    "\n",
    "# Initialize weights as glove vectors    \n",
    "\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
    "    'out': tf.Variable(tf.constant(0.0, shape=[embedding_dim,vocab_size ]),\n",
    "                trainable=False, name=\"W\")\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size + 1]))\n",
    "}\n",
    "\n",
    "\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n",
    "embedding_init = weights['out'].assign(embedding_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 13)\n",
      "(2, 26)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(4, 13)\n",
    "print(a.shape)\n",
    "\n",
    "b = np.reshape(a, (2,26))\n",
    "\n",
    "print(b.shape)\n",
    "\n",
    "\n",
    "\n",
    "#for (x,y), value in numpy.ndenumerate(a):\n",
    "#...  print x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x):\n",
    "\n",
    "   \n",
    "    #  data input shape: (batch_size, timesteps, n_input)\n",
    "    \n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell for layer 1\n",
    "    lstm_fw_cell_1 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell for layer 1 \n",
    "    lstm_bw_cell_1 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "     # Forward direction cell for layer 2\n",
    "    lstm_fw_cell_2 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell for layer 2 \n",
    "    lstm_bw_cell_2 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    # Forward direction cell for layer 3\n",
    "    lstm_fw_cell_3 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell for layer 3 \n",
    "    lstm_bw_cell_3 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    # Forward direction cell for layer 4\n",
    "    lstm_fw_cell_4 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell for layer 4 \n",
    "    lstm_bw_cell_4 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "     # Forward direction cell for layer 5\n",
    "    lstm_fw_cell_5 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell for layer 5 \n",
    "    lstm_bw_cell_5 = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    cells_fw=[lstm_fw_cell_1,lstm_fw_cell_2,lstm_fw_cell_3,lstm_fw_cell_4,lstm_fw_cell_5]\n",
    "    cells_bw=[lstm_bw_cell_1, lstm_bw_cell_2,lstm_bw_cell_3,lstm_bw_cell_4,lstm_bw_cell_5]\n",
    "\n",
    "    outputs, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(cells_fw, cells_bw, x,\n",
    "                                              dtype=tf.float32)\n",
    "    # final linear dense layer\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']\n",
    "    #return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 300, 101)\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    input_features=np.random.rand(2,300,80)\n",
    "    print(sess.run(logits, feed_dict={X: input_features}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
